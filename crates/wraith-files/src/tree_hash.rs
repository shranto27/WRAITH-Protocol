//! BLAKE3 tree hashing for file integrity verification.
//!
//! Implements a Merkle tree structure where each file is divided into chunks,
//! and each chunk is hashed individually. The chunk hashes form the leaf nodes
//! of a binary tree, with parent nodes computed by hashing the concatenation
//! of their children.

use blake3::Hasher;
use std::fs::File;
use std::io::{self, Read};
use std::path::Path;

/// File tree hash structure
///
/// Contains the root hash (for quick verification) and all chunk hashes
/// (for selective verification of individual chunks).
#[derive(Debug, Clone)]
pub struct FileTreeHash {
    /// Merkle root hash
    pub root: [u8; 32],
    /// Chunk hashes (leaf nodes of the tree)
    pub chunks: Vec<[u8; 32]>,
}

impl FileTreeHash {
    /// Create a new tree hash
    #[must_use]
    pub fn new(root: [u8; 32], chunks: Vec<[u8; 32]>) -> Self {
        Self { root, chunks }
    }

    /// Get number of chunks
    #[must_use]
    pub fn chunk_count(&self) -> usize {
        self.chunks.len()
    }

    /// Verify a chunk against its expected hash
    #[must_use]
    pub fn verify_chunk(&self, chunk_index: usize, chunk_data: &[u8]) -> bool {
        if chunk_index >= self.chunks.len() {
            return false;
        }

        let computed_hash = blake3::hash(chunk_data);
        computed_hash.as_bytes() == &self.chunks[chunk_index]
    }

    /// Get chunk hash
    #[must_use]
    pub fn get_chunk_hash(&self, chunk_index: usize) -> Option<&[u8; 32]> {
        self.chunks.get(chunk_index)
    }
}

/// Compute tree hash for a file
///
/// # Errors
///
/// Returns an error if the file cannot be opened or read.
///
/// # Example
///
/// ```no_run
/// use wraith_files::tree_hash::compute_tree_hash;
///
/// let tree = compute_tree_hash("/path/to/file", 256 * 1024)?;
/// println!("Root hash: {:?}", tree.root);
/// println!("Chunks: {}", tree.chunk_count());
/// # Ok::<(), std::io::Error>(())
/// ```
pub fn compute_tree_hash<P: AsRef<Path>>(path: P, chunk_size: usize) -> io::Result<FileTreeHash> {
    let mut file = File::open(path)?;
    let total_size = file.metadata()?.len();

    let num_chunks = total_size.div_ceil(chunk_size as u64);
    let mut chunk_hashes = Vec::with_capacity(num_chunks as usize);

    // Hash each chunk
    let mut buffer = vec![0u8; chunk_size];

    loop {
        let bytes_read = file.read(&mut buffer)?;
        if bytes_read == 0 {
            break;
        }

        let chunk_hash = blake3::hash(&buffer[..bytes_read]);
        chunk_hashes.push(*chunk_hash.as_bytes());
    }

    // Build Merkle tree
    let root = compute_merkle_root(&chunk_hashes);

    Ok(FileTreeHash {
        root,
        chunks: chunk_hashes,
    })
}

/// Compute Merkle root from leaf hashes
///
/// Implements a binary Merkle tree where parent nodes are computed by
/// hashing the concatenation of their two children. If there's an odd
/// number of nodes at any level, the last node is promoted to the next level.
///
/// # Example
///
/// ```
/// use wraith_files::tree_hash::compute_merkle_root;
///
/// let leaves = vec![[1u8; 32], [2u8; 32], [3u8; 32], [4u8; 32]];
/// let root = compute_merkle_root(&leaves);
/// ```
#[must_use]
pub fn compute_merkle_root(leaves: &[[u8; 32]]) -> [u8; 32] {
    if leaves.is_empty() {
        return [0u8; 32];
    }

    if leaves.len() == 1 {
        return leaves[0];
    }

    let mut current_level = leaves.to_vec();

    while current_level.len() > 1 {
        let mut next_level = Vec::new();

        for pair in current_level.chunks(2) {
            let hash = if pair.len() == 2 {
                // Hash concatenation of two nodes
                let mut hasher = Hasher::new();
                hasher.update(&pair[0]);
                hasher.update(&pair[1]);
                *hasher.finalize().as_bytes()
            } else {
                // Odd number, promote single node
                pair[0]
            };

            next_level.push(hash);
        }

        current_level = next_level;
    }

    current_level[0]
}

/// Verify chunk data against tree
///
/// # Example
///
/// ```no_run
/// use wraith_files::tree_hash::{compute_tree_hash, verify_chunk};
///
/// let tree = compute_tree_hash("/path/to/file", 256 * 1024)?;
/// let chunk_data = vec![0u8; 256 * 1024];
/// assert!(verify_chunk(0, &chunk_data, &tree));
/// # Ok::<(), std::io::Error>(())
/// ```
#[must_use]
pub fn verify_chunk(chunk_index: usize, chunk_data: &[u8], tree: &FileTreeHash) -> bool {
    tree.verify_chunk(chunk_index, chunk_data)
}

/// Incremental tree hasher for streaming data
///
/// Useful for hashing data as it's being transferred without needing
/// to buffer the entire file in memory.
///
/// # Example
///
/// ```
/// use wraith_files::tree_hash::IncrementalTreeHasher;
///
/// let mut hasher = IncrementalTreeHasher::new(256 * 1024);
///
/// // Feed data in chunks
/// hasher.update(&[0xAA; 1024]);
/// hasher.update(&[0xBB; 1024]);
///
/// let tree = hasher.finalize();
/// ```
pub struct IncrementalTreeHasher {
    chunk_hashes: Vec<[u8; 32]>,
    current_buffer: Vec<u8>,
    chunk_size: usize,
}

impl IncrementalTreeHasher {
    /// Create a new incremental hasher
    #[must_use]
    pub fn new(chunk_size: usize) -> Self {
        Self {
            chunk_hashes: Vec::new(),
            current_buffer: Vec::new(),
            chunk_size,
        }
    }

    /// Update with new data
    ///
    /// Data is buffered until a complete chunk is accumulated, at which
    /// point it's hashed and added to the chunk list.
    pub fn update(&mut self, data: &[u8]) {
        self.current_buffer.extend_from_slice(data);

        // Process complete chunks
        while self.current_buffer.len() >= self.chunk_size {
            let chunk = self
                .current_buffer
                .drain(..self.chunk_size)
                .collect::<Vec<_>>();
            let hash = blake3::hash(&chunk);
            self.chunk_hashes.push(*hash.as_bytes());
        }
    }

    /// Get number of complete chunks processed
    #[must_use]
    pub fn chunk_count(&self) -> usize {
        self.chunk_hashes.len()
    }

    /// Get buffered byte count (not yet hashed)
    #[must_use]
    pub fn buffered_bytes(&self) -> usize {
        self.current_buffer.len()
    }

    /// Finalize and get tree hash
    ///
    /// Hashes any remaining buffered data and computes the Merkle root.
    #[must_use]
    pub fn finalize(mut self) -> FileTreeHash {
        // Hash remaining data
        if !self.current_buffer.is_empty() {
            let hash = blake3::hash(&self.current_buffer);
            self.chunk_hashes.push(*hash.as_bytes());
        }

        let root = compute_merkle_root(&self.chunk_hashes);

        FileTreeHash {
            root,
            chunks: self.chunk_hashes,
        }
    }
}

/// Compute tree hash from in-memory data
///
/// # Example
///
/// ```
/// use wraith_files::tree_hash::compute_tree_hash_from_data;
///
/// let data = vec![0xAA; 1024 * 1024];
/// let tree = compute_tree_hash_from_data(&data, 256 * 1024);
/// ```
#[must_use]
pub fn compute_tree_hash_from_data(data: &[u8], chunk_size: usize) -> FileTreeHash {
    let mut chunk_hashes = Vec::new();

    for chunk in data.chunks(chunk_size) {
        let hash = blake3::hash(chunk);
        chunk_hashes.push(*hash.as_bytes());
    }

    let root = compute_merkle_root(&chunk_hashes);

    FileTreeHash {
        root,
        chunks: chunk_hashes,
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::io::Write;
    use tempfile::NamedTempFile;

    #[test]
    fn test_tree_hash_computation() {
        let mut temp_file = NamedTempFile::new().unwrap();
        let data = vec![0xAA; 1024 * 1024]; // 1 MB
        temp_file.write_all(&data).unwrap();
        temp_file.flush().unwrap();

        let tree = compute_tree_hash(temp_file.path(), 256 * 1024).unwrap();

        assert_eq!(tree.chunks.len(), 4); // 1MB / 256KB
        assert_ne!(tree.root, [0u8; 32]);
    }

    #[test]
    fn test_chunk_verification() {
        let mut temp_file = NamedTempFile::new().unwrap();
        let data = vec![0xAA; 512 * 1024]; // 512 KB
        temp_file.write_all(&data).unwrap();
        temp_file.flush().unwrap();

        let tree = compute_tree_hash(temp_file.path(), 256 * 1024).unwrap();

        // Verify first chunk
        let chunk = vec![0xAA; 256 * 1024];
        assert!(verify_chunk(0, &chunk, &tree));

        // Verify with wrong data
        let wrong_chunk = vec![0xBB; 256 * 1024];
        assert!(!verify_chunk(0, &wrong_chunk, &tree));
    }

    #[test]
    fn test_incremental_hasher() {
        let data = vec![0xAA; 1024 * 1024];

        let mut hasher = IncrementalTreeHasher::new(256 * 1024);

        // Feed data in 64KB chunks
        for chunk in data.chunks(64 * 1024) {
            hasher.update(chunk);
        }

        let tree = hasher.finalize();

        assert_eq!(tree.chunks.len(), 4);
    }

    #[test]
    fn test_merkle_root_single_leaf() {
        let leaf = [[1u8; 32]];
        let root = compute_merkle_root(&leaf);
        assert_eq!(root, leaf[0]);
    }

    #[test]
    fn test_merkle_root_multiple_leaves() {
        let leaves = vec![[1u8; 32], [2u8; 32], [3u8; 32], [4u8; 32]];
        let root = compute_merkle_root(&leaves);

        // Root should be different from any leaf
        for leaf in &leaves {
            assert_ne!(root, *leaf);
        }
    }

    #[test]
    fn test_merkle_root_empty() {
        let leaves: Vec<[u8; 32]> = vec![];
        let root = compute_merkle_root(&leaves);
        assert_eq!(root, [0u8; 32]);
    }

    #[test]
    fn test_merkle_root_odd_number() {
        let leaves = vec![[1u8; 32], [2u8; 32], [3u8; 32]];
        let root = compute_merkle_root(&leaves);
        assert_ne!(root, [0u8; 32]);
    }

    #[test]
    fn test_tree_hash_from_data() {
        let data = vec![0xCC; 1024 * 1024];
        let tree = compute_tree_hash_from_data(&data, 256 * 1024);

        assert_eq!(tree.chunks.len(), 4);
        assert_ne!(tree.root, [0u8; 32]);
    }

    #[test]
    fn test_incremental_vs_batch() {
        let data = vec![0xDD; 1024 * 1024];

        // Batch hash
        let tree_batch = compute_tree_hash_from_data(&data, 256 * 1024);

        // Incremental hash
        let mut hasher = IncrementalTreeHasher::new(256 * 1024);
        for chunk in data.chunks(64 * 1024) {
            hasher.update(chunk);
        }
        let tree_incremental = hasher.finalize();

        // Should produce same result
        assert_eq!(tree_batch.root, tree_incremental.root);
        assert_eq!(tree_batch.chunks, tree_incremental.chunks);
    }

    #[test]
    fn test_file_tree_hash_methods() {
        let chunks = vec![[1u8; 32], [2u8; 32], [3u8; 32]];
        let root = compute_merkle_root(&chunks);
        let tree = FileTreeHash::new(root, chunks.clone());

        assert_eq!(tree.chunk_count(), 3);
        assert_eq!(tree.get_chunk_hash(0), Some(&[1u8; 32]));
        assert_eq!(tree.get_chunk_hash(3), None);

        // Verify chunk
        let chunk_data = [0u8; 100];
        let expected_hash = blake3::hash(&chunk_data);
        let tree_with_hash = FileTreeHash::new([0u8; 32], vec![*expected_hash.as_bytes()]);
        assert!(tree_with_hash.verify_chunk(0, &chunk_data));
    }

    #[test]
    fn test_incremental_hasher_buffering() {
        let mut hasher = IncrementalTreeHasher::new(1024);

        hasher.update(&[0xAA; 512]);
        assert_eq!(hasher.chunk_count(), 0);
        assert_eq!(hasher.buffered_bytes(), 512);

        hasher.update(&[0xBB; 512]);
        assert_eq!(hasher.chunk_count(), 1);
        assert_eq!(hasher.buffered_bytes(), 0);

        hasher.update(&[0xCC; 256]);
        assert_eq!(hasher.chunk_count(), 1);
        assert_eq!(hasher.buffered_bytes(), 256);

        let tree = hasher.finalize();
        assert_eq!(tree.chunk_count(), 2); // 1 complete + 1 partial
    }
}
